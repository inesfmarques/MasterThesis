{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.3"
    },
    "colab": {
      "name": "Model.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WWPCqRvxP3z6",
        "colab_type": "text"
      },
      "source": [
        "# Import libraries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HHS7waePPv-k",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "total = 217\n",
        "\n",
        "import time\n",
        "import numpy as np\n",
        "sd = 30\n",
        "\n",
        "import pandas as pd\n",
        "import matplotlib as mpl\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "%tensorflow_version 2.x\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from keras import metrics\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, LSTM, GRU\n",
        "from keras.layers import LeakyReLU, Input, Dropout\n",
        "from keras.utils import to_categorical\n",
        "from keras.callbacks import EarlyStopping\n",
        "from keras.wrappers.scikit_learn import KerasClassifier\n",
        "\n",
        "import sklearn\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.metrics import plot_confusion_matrix\n",
        "from sklearn.metrics import f1_score\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.model_selection import validation_curve\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.model_selection import KFold\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "from sklearn.linear_model import SGDClassifier\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "from sklearn.naive_bayes import ComplementNB\n",
        "from sklearn.naive_bayes import BernoulliNB\n",
        "from sklearn.naive_bayes import CategoricalNB\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.neural_network import MLPClassifier"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CjDH9xcIQH4p",
        "colab_type": "text"
      },
      "source": [
        "# Load Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UAlKW8j8RLs2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "%cd drive/My Drive/partilhado/\n",
        "\n",
        "dataset = pd.read_csv('dataset-final.csv', sep=',')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2i_YakLSR8Rq",
        "colab_type": "text"
      },
      "source": [
        "# Split Data\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": false,
        "id": "R3uJn1oQPv-8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df = dataset.to_numpy()\n",
        "x = df[:, 1:]\n",
        "y = df[:, 0]\n",
        "\n",
        "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size = 0.2, random_state = sd)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cwXdCIxYPv_B",
        "colab_type": "text"
      },
      "source": [
        "# Stochastic Gradient Descent"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X7lk7dxbXSI7",
        "colab_type": "text"
      },
      "source": [
        "## Grid Search"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "FfVgqc8uj3Px",
        "colab": {}
      },
      "source": [
        "parameters = {'alpha': np.logspace(-6, -3, 10), 'penalty' : ['l1','l2']}\n",
        "\n",
        "st=time.time()\n",
        "search = GridSearchCV(SGDClassifier(loss = 'log', n_jobs = -1, random_state = sd),\n",
        "                   parameters, cv = 3, verbose = 11, n_jobs = -1, scoring = 'f1_weighted')\n",
        "search.fit(x_train, y_train)\n",
        "print(time.time()-st)\n",
        "\n",
        "print(search.best_params_)\n",
        "print(search.best_score_)\n",
        "print(search.cv_results_['std_test_score'][search.best_index_])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sSC9Z2TxtgJR",
        "colab_type": "text"
      },
      "source": [
        "## Confusion Matrix"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fPKYMoT-ticZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "st=time.time()\n",
        "model = SGDClassifier(loss = 'log', penalty = 'l1', alpha = 0.0001, n_jobs = -1, random_state = sd).fit(x_train,y_train)\n",
        "print(time.time()-st)\n",
        "\n",
        "yt = model.predict(x_test)\n",
        "\n",
        "m = confusion_matrix(y_test, yt, normalize = 'true')\n",
        "tick = sorted(set(y_test))\n",
        "fig, ax = plt.subplots(figsize=(30,15))\n",
        "conf = sns.heatmap(m, xticklabels = tick, yticklabels = tick, cmap=plt.cm.Blues)\n",
        "plt.ylabel('True Label')\n",
        "plt.xlabel('Predicted Label')\n",
        "conf.xaxis.tick_top()\n",
        "conf.xaxis.set_label_position('top')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DNz_4FMgPv_J",
        "colab_type": "text"
      },
      "source": [
        "#Logistic Regression"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0XCEBvUok4uT",
        "colab_type": "text"
      },
      "source": [
        "## Grid Search"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "feJ3GzjxphUn",
        "colab": {}
      },
      "source": [
        "parameters = {'C' : np.logspace(-1, 3, 10), 'solver' : ['lbfgs']}\n",
        "\n",
        "st=time.time()\n",
        "search = GridSearchCV(LogisticRegression(multi_class = 'multinomial', n_jobs = -1, random_state = sd),\n",
        "                   parameters, cv = 3, verbose = 11, n_jobs = -1, scoring = 'f1_weighted')\n",
        "search.fit(x_train,y_train)\n",
        "print(time.time()-st)\n",
        "\n",
        "print(search.best_params_)\n",
        "print(search.best_score_)\n",
        "print(search.cv_results_['std_test_score'][search.best_index_])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vFq3t6xIW2hB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "parameters = {'C' : np.logspace(-1, 3, 10), 'solver' : ['sag']}\n",
        "\n",
        "st=time.time()\n",
        "search = GridSearchCV(LogisticRegression(max_iter = 400, multi_class = 'multinomial', n_jobs = -1, random_state = sd),\n",
        "                   parameters, cv = 3, verbose = 11, n_jobs = -1, scoring = 'f1_weighted')\n",
        "search.fit(x_train,y_train)\n",
        "print(time.time()-st)\n",
        "\n",
        "print(search.best_params_)\n",
        "print(search.best_score_)\n",
        "print(search.cv_results_['std_test_score'][search.best_index_])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "6U5HwWE-qZqY"
      },
      "source": [
        "## Confusion Matrix"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "aTWLoIa7qZqd",
        "colab": {}
      },
      "source": [
        "st=time.time()\n",
        "model = LogisticRegression(multi_class = 'multinomial', n_jobs = -1, random_state = sd).fit(x_train,y_train)\n",
        "print(time.time()-st)\n",
        "\n",
        "yt = model.predict(x_test)\n",
        "\n",
        "m = confusion_matrix(y_test, yt, normalize = 'true')\n",
        "tick = sorted(set(y_test))\n",
        "fig, ax = plt.subplots(figsize=(30,15))\n",
        "conf = sns.heatmap(m, xticklabels = tick, yticklabels = tick, cmap=plt.cm.Blues)\n",
        "plt.ylabel('True Label')\n",
        "plt.xlabel('Predicted Label')\n",
        "conf.xaxis.tick_top()\n",
        "conf.xaxis.set_label_position('top')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S6HkErqlPv_R",
        "colab_type": "text"
      },
      "source": [
        "# Naive Bayes"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hY0MkN7wVNz-",
        "colab_type": "text"
      },
      "source": [
        "##BernoulliNB"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WHcT43HNl82P",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "param = np.logspace(-4, 3, 50)\n",
        "parameters = {'alpha': param}\n",
        "\n",
        "st=time.time()\n",
        "search = GridSearchCV(BernoulliNB(), parameters, cv = 3, return_train_score = True,\n",
        "                      verbose = 10, n_jobs = -1, scoring = 'f1_weighted')\n",
        "search.fit(x_train, y_train)\n",
        "print(time.time()-st)\n",
        "\n",
        "print(search.best_params_)\n",
        "print(search.best_score_)\n",
        "print(search.cv_results_['std_test_score'][search.best_index_])\n",
        "\n",
        "results = search.cv_results_\n",
        "trn_scores_mean = results['mean_train_score']\n",
        "trn_scores_std = results['std_train_score']\n",
        "val_scores_mean = results['mean_test_score']\n",
        "val_scores_std = results['std_test_score']\n",
        "\n",
        "\n",
        "plt.title(\"Validation Curve with BernoulliNB\")\n",
        "plt.xlabel(r\"$\\alpha$\")\n",
        "plt.ylabel(\"F1-score\")\n",
        "plt.semilogx(param, trn_scores_mean, label=\"Training score\", color=\"darkorange\", lw=2)\n",
        "plt.fill_between(param, trn_scores_mean - trn_scores_std,\n",
        "                 trn_scores_mean + trn_scores_std, alpha=0.2,\n",
        "                 color=\"darkorange\", lw=2)\n",
        "plt.semilogx(param, val_scores_mean, label=\"Cross-validation score\", color=\"navy\", lw=2)\n",
        "plt.fill_between(param, val_scores_mean - val_scores_std,\n",
        "                 val_scores_mean + val_scores_std, alpha=0.2,\n",
        "                 color=\"navy\", lw=2)\n",
        "plt.legend(loc=\"best\")\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PAGl9QIzVRen",
        "colab_type": "text"
      },
      "source": [
        "##ComplementNB"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jaKH7xhBP0N2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "param = np.logspace(0, 3, 50)\n",
        "parameters = {'alpha': param}\n",
        "\n",
        "st=time.time()\n",
        "search = GridSearchCV(ComplementNB(), parameters, cv = 3, return_train_score = True,\n",
        "                      verbose = 10, n_jobs = -1, scoring = 'f1_weighted')\n",
        "search.fit(x_train, y_train)\n",
        "print(time.time()-st)\n",
        "\n",
        "print(search.best_params_)\n",
        "print(search.best_score_)\n",
        "print(search.cv_results_['std_test_score'][search.best_index_])\n",
        "\n",
        "results = search.cv_results_\n",
        "trn_scores_mean = results['mean_train_score']\n",
        "trn_scores_std = results['std_train_score']\n",
        "val_scores_mean = results['mean_test_score']\n",
        "val_scores_std = results['std_test_score']\n",
        "\n",
        "plt.title(\"Validation Curve with ComplementNB\")\n",
        "plt.xlabel(r\"$\\alpha$\")\n",
        "plt.ylabel(\"F1-score\")\n",
        "plt.semilogx(param, trn_scores_mean, label=\"Training score\", color=\"darkorange\", lw=2)\n",
        "plt.fill_between(param, trn_scores_mean - trn_scores_std,\n",
        "                 trn_scores_mean + trn_scores_std, alpha=0.2,\n",
        "                 color=\"darkorange\", lw=2)\n",
        "plt.semilogx(param, val_scores_mean, label=\"Cross-validation score\", color=\"navy\", lw=2)\n",
        "plt.fill_between(param, val_scores_mean - val_scores_std,\n",
        "                 val_scores_mean + val_scores_std, alpha=0.2,\n",
        "                 color=\"navy\", lw=2)\n",
        "plt.legend(loc=\"best\")\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "bKHeRtrQ6R7M"
      },
      "source": [
        "## Confusion Matrix"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "CkeOQRms6R7P",
        "colab": {}
      },
      "source": [
        "st=time.time()\n",
        "model = BernoulliNB(alpha = 100).fit(x_train,y_train)\n",
        "#model = ComplementNB(alpha = 184).fit(x_train,y_train)\n",
        "print(time.time()-st)\n",
        "\n",
        "yt = model.predict(x_test)\n",
        "\n",
        "m = confusion_matrix(y_test, yt, normalize = 'true')\n",
        "tick = sorted(set(y_test))\n",
        "fig, ax = plt.subplots(figsize=(30,15))\n",
        "conf = sns.heatmap(m, xticklabels = tick, yticklabels = tick, cmap=plt.cm.Blues)\n",
        "plt.ylabel('True Label')\n",
        "plt.xlabel('Predicted Label')\n",
        "conf.xaxis.tick_top()\n",
        "conf.xaxis.set_label_position('top')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "czcoJ8c6q63S",
        "colab_type": "text"
      },
      "source": [
        "# Random Forest"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fcWvlik9ldxf",
        "colab_type": "text"
      },
      "source": [
        "## Grid Search"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rH6Y7xpf1wWf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "parameters = {'n_estimators' : list(range(50,150,25)), 'criterion' : ['gini','entropy'],\n",
        "              'bootstrap' : [True,False], 'max_features' : ['auto', 'sqrt', 'log2']}\n",
        "\n",
        "st=time.time()\n",
        "search = GridSearchCV(RandomForestClassifier(n_jobs = -1, random_state = sd),\n",
        "                   parameters, cv = 3, verbose = 10, n_jobs = -1, scoring = 'f1_weighted')\n",
        "search.fit(x_train, y_train)\n",
        "print(time.time()-st)\n",
        "\n",
        "print(search.best_params_)\n",
        "print(search.best_score_)\n",
        "print(search.cv_results_['std_test_score'][search.best_index_])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_7lubgMPRmam",
        "colab_type": "text"
      },
      "source": [
        "## Validation Curves"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "QyJNkouxRhDs",
        "colab": {}
      },
      "source": [
        "param = list(range(2,52,2))\n",
        "parameters = {'min_samples_split' : param}\n",
        "\n",
        "st=time.time()\n",
        "search = GridSearchCV(RandomForestClassifier(n_estimators = 75, n_jobs = -1, random_state = sd),\n",
        "                      parameters, cv = 3, return_train_score = True,\n",
        "                      verbose = 10, n_jobs = -1, scoring = 'f1_weighted')\n",
        "search.fit(x_train, y_train)\n",
        "print(time.time()-st)\n",
        "\n",
        "print(search.best_params_)\n",
        "print(search.best_score_)\n",
        "print(search.cv_results_['std_test_score'][search.best_index_])\n",
        "\n",
        "results = search.cv_results_\n",
        "trn_scores_mean = results['mean_train_score']\n",
        "trn_scores_std = results['std_train_score']\n",
        "val_scores_mean = results['mean_test_score']\n",
        "val_scores_std = results['std_test_score']\n",
        "\n",
        "\n",
        "plt.title('Validation Curve for min_samples_split')\n",
        "plt.xlabel('min_samples_split')\n",
        "plt.ylabel('F1-score')\n",
        "plt.semilogx(param, trn_scores_mean, label='Training score', color='darkorange', lw=2)\n",
        "plt.fill_between(param, trn_scores_mean - trn_scores_std,\n",
        "                 trn_scores_mean + trn_scores_std, alpha=0.2,\n",
        "                 color='darkorange', lw=2)\n",
        "plt.semilogx(param, val_scores_mean, label='Cross-validation score', color='navy', lw=2)\n",
        "plt.fill_between(param, val_scores_mean - val_scores_std,\n",
        "                 val_scores_mean + val_scores_std, alpha=0.2,\n",
        "                 color='navy', lw=2)\n",
        "plt.legend(loc='best')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "nscykVE0ReMK",
        "colab": {}
      },
      "source": [
        "param = list(range(1,51,2))\n",
        "parameters = {'min_samples_leaf' : param}\n",
        "\n",
        "st=time.time()\n",
        "search = GridSearchCV(RandomForestClassifier(min_samples_split = 8, n_estimators = 75, n_jobs = -1, random_state = sd),\n",
        "                      parameters, cv = 3, return_train_score = True,\n",
        "                      verbose = 10, n_jobs = -1, scoring = 'f1_weighted')\n",
        "search.fit(x_train, y_train)\n",
        "print(time.time()-st)\n",
        "\n",
        "print(search.best_params_)\n",
        "print(search.best_score_)\n",
        "print(search.cv_results_['std_test_score'][search.best_index_])\n",
        "\n",
        "results = search.cv_results_\n",
        "trn_scores_mean = results['mean_train_score']\n",
        "trn_scores_std = results['std_train_score']\n",
        "val_scores_mean = results['mean_test_score']\n",
        "val_scores_std = results['std_test_score']\n",
        "\n",
        "\n",
        "plt.title('Validation Curve for min_samples_leaf')\n",
        "plt.xlabel('min_samples_leaf')\n",
        "plt.ylabel('F1-score')\n",
        "plt.semilogx(param, trn_scores_mean, label='Training score', color='darkorange', lw=2)\n",
        "plt.fill_between(param, trn_scores_mean - trn_scores_std,\n",
        "                 trn_scores_mean + trn_scores_std, alpha=0.2,\n",
        "                 color='darkorange', lw=2)\n",
        "plt.semilogx(param, val_scores_mean, label='Cross-validation score', color='navy', lw=2)\n",
        "plt.fill_between(param, val_scores_mean - val_scores_std,\n",
        "                 val_scores_mean + val_scores_std, alpha=0.2,\n",
        "                 color='navy', lw=2)\n",
        "plt.legend(loc='best')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "qdR0xf9aREMu"
      },
      "source": [
        "## Confusion Matrix"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "cx3bPRaYREMy",
        "colab": {}
      },
      "source": [
        "st=time.time()\n",
        "model = RandomForestClassifier(n_estimators = 75, min_samples_split = 8, n_jobs = -1, random_state = sd).fit(x_train,y_train)\n",
        "print(time.time()-st)\n",
        "\n",
        "yt = model.predict(x_test)\n",
        "\n",
        "m = confusion_matrix(y_test, yt, normalize = 'true')\n",
        "tick = sorted(set(y_test))\n",
        "fig, ax = plt.subplots(figsize=(30,15))\n",
        "conf = sns.heatmap(m, xticklabels = tick, yticklabels = tick, cmap=plt.cm.Blues)\n",
        "plt.ylabel('True Label')\n",
        "plt.xlabel('Predicted Label')\n",
        "conf.xaxis.tick_top()\n",
        "conf.xaxis.set_label_position('top')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sICNjgYnPv_q",
        "colab_type": "text"
      },
      "source": [
        "# MLP"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5RqhPk4xlo2C",
        "colab_type": "text"
      },
      "source": [
        "## Grid Search"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "R1TOBfEobbNI",
        "colab": {}
      },
      "source": [
        "parameters = {'hidden_layer_sizes' : list(range(50,100,25)), 'activation' : ['tanh','relu']}\n",
        "\n",
        "st=time.time()\n",
        "search = GridSearchCV(MLPClassifier(max_iter = 400, hidden_layer_sizes = (75), random_state = sd),\n",
        "                      parameters, cv = 3, verbose = 10, n_jobs = -1, scoring = 'f1_weighted')\n",
        "search.fit(x_train, y_train)\n",
        "print(time.time()-st)\n",
        "\n",
        "print(search.best_params_)\n",
        "print(search.best_score_)\n",
        "print(search.cv_results_['std_test_score'][search.best_index_])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vj4KAYerS1ep",
        "colab_type": "text"
      },
      "source": [
        "## Validation Curve"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "L5W8nIB8AbV1",
        "colab": {}
      },
      "source": [
        "param = np.logspace(-12,-8,20)\n",
        "parameters = {'alpha' : param}\n",
        "\n",
        "st=time.time()\n",
        "search = GridSearchCV(MLPClassifier(hidden_layer_sizes = (75), early_stopping = True, random_state = sd),\n",
        "                      parameters, cv = 3, return_train_score = True,\n",
        "                      verbose = 10, n_jobs = -1, scoring = 'f1_weighted')\n",
        "search.fit(x_train, y_train)\n",
        "print(time.time()-st)\n",
        "\n",
        "print(search.best_params_)\n",
        "print(search.best_score_)\n",
        "print(search.cv_results_['std_test_score'][search.best_index_])\n",
        "\n",
        "results = search.cv_results_\n",
        "trn_scores_mean = results['mean_train_score']\n",
        "trn_scores_std = results['std_train_score']\n",
        "val_scores_mean = results['mean_test_score']\n",
        "val_scores_std = results['std_test_score']\n",
        "\n",
        "\n",
        "plt.title('Validation Curve with MLP')\n",
        "plt.xlabel(r'$\\alpha$')\n",
        "plt.ylabel('F1-score')\n",
        "plt.semilogx(param, trn_scores_mean, label='Training score', color='darkorange', lw=2)\n",
        "plt.fill_between(param, trn_scores_mean - trn_scores_std,\n",
        "                 trn_scores_mean + trn_scores_std, alpha=0.2,\n",
        "                 color='darkorange', lw=2)\n",
        "plt.semilogx(param, val_scores_mean, label='Cross-validation score', color='navy', lw=2)\n",
        "plt.fill_between(param, val_scores_mean - val_scores_std,\n",
        "                 val_scores_mean + val_scores_std, alpha=0.2,\n",
        "                 color='navy', lw=2)\n",
        "plt.legend(loc='best')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "efL3RU28rWul",
        "colab_type": "text"
      },
      "source": [
        "## Confusion Matrix"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "8asAkhwQQzTk",
        "colab": {}
      },
      "source": [
        "st=time.time()\n",
        "model = MLPClassifier(hidden_layer_sizes = (75), alpha = 10e-10, early_stopping = True, random_state = sd).fit(x_train,y_train)\n",
        "print(time.time()-st)\n",
        "\n",
        "yt = model.predict(x_test)\n",
        "\n",
        "m = confusion_matrix(y_test, yt, normalize = 'true')\n",
        "tick = sorted(set(y_test))\n",
        "fig, ax = plt.subplots(figsize=(30,15))\n",
        "conf = sns.heatmap(m, xticklabels = tick, yticklabels = tick, cmap=plt.cm.Blues)\n",
        "plt.ylabel('True Label')\n",
        "plt.xlabel('Predicted Label')\n",
        "conf.xaxis.tick_top()\n",
        "conf.xaxis.set_label_position('top')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fQ7V5qoq5hZA",
        "colab_type": "text"
      },
      "source": [
        "# Scores Comparison"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ycoEUaVQOd1P",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = SGDClassifier(loss = 'log', penalty = 'l1', alpha = 0.0001, n_jobs = -1, random_state = sd).fit(x_train,y_train)\n",
        "yv = model.predict(x_test)\n",
        "c1 = classification_report(y_test, yv, digits=3, output_dict = True)\n",
        "\n",
        "model = MLPClassifier(hidden_layer_sizes = (75), alpha = 10e-10, early_stopping = True, random_state = sd).fit(x_train,y_train)\n",
        "yv = model.predict(x_test)\n",
        "c2 = classification_report(y_test, yv, digits=3, output_dict = True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8gC7VEBT5pSb",
        "colab_type": "text"
      },
      "source": [
        "## Classification reports difference"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9aIPWTXpQO1d",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def rec_diff(d1,d2):\n",
        "  diff = dict()\n",
        "  for k,v1 in d1.items():\n",
        "    if isinstance(v1, dict):\n",
        "      diff[k] = rec_diff(v1, d2[k])\n",
        "    else:\n",
        "      if k != 'support':\n",
        "        diff[k] = v1 - d2[k]\n",
        "      else:\n",
        "        diff[k] = v1\n",
        "  return diff\n",
        "\n",
        "# mlp - sgd\n",
        "c3 = rec_diff(c2, c1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OHKDWd9DTmrD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for k in c3:\n",
        "  if k.isnumeric() and (c3[k]['precision'] != 0 or c3[k]['recall'] != 0):\n",
        "    print(k,c3[k],'\\n')\n",
        "  elif k.isnumeric() == False:\n",
        "    print(k,c3[k],'\\n')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K_vB_atOXcTH",
        "colab_type": "text"
      },
      "source": [
        "# Keras NN"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "owKv_wCiqSlX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras import backend as K\n",
        "\n",
        "ytrain = to_categorical(y_train, num_classes = total)\n",
        "yval = to_categorical(y_test, num_classes = total)\n",
        "\n",
        "def f1_weighted(true, pred):\n",
        "  predLabels = K.argmax(pred, axis=-1)\n",
        "  pred = K.one_hot(predLabels, total) \n",
        "\n",
        "  actual_positives = K.sum(true, axis=0)       # = TP + FN\n",
        "  pred_positives = K.sum(pred, axis=0)         # = TP + FP\n",
        "  true_positives = K.sum(true * pred, axis=0)  # = TP\n",
        "\n",
        "  precision = (true_positives + K.epsilon()) / (pred_positives + K.epsilon()) \n",
        "  recall = (true_positives + K.epsilon()) / (actual_positives + K.epsilon()) \n",
        "  #both = 1 if ground_positives == 0 or pred_positives == 0\n",
        "\n",
        "  f1 = 2 * (precision * recall) / (precision + recall)\n",
        "\n",
        "  weighted_f1 = f1 * actual_positives / K.sum(actual_positives)\n",
        "  weighted_f1 = K.sum(weighted_f1)\n",
        "\n",
        "  return weighted_f1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s3Upr3hCTeho",
        "colab_type": "text"
      },
      "source": [
        "## Cross Validation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "3H7x2_PS-EWi",
        "colab": {}
      },
      "source": [
        "kfold = StratifiedKFold(n_splits = 10)\n",
        "cvscores = []\n",
        "\n",
        "st=time.time()\n",
        "for train, val in kfold.split(x_train, y_train):\n",
        "\t# create model\n",
        "\tmodel = Sequential()\n",
        "\tmodel.add(Dense(300, input_dim = 565, activation = 'relu'))\n",
        "\tmodel.add(Dropout(0.2))\n",
        "\tmodel.add(LeakyReLU())\n",
        "\tmodel.add(Dropout(0.3))\n",
        "\tmodel.add(Dense(total, activation = 'softmax'))\n",
        " \n",
        "\tmodel.compile(loss = 'categorical_crossentropy', optimizer = 'adam', metrics = [f1_weighted])\n",
        "\tmodel.fit(x_train[train], ytrain[train], batch_size = 1000, epochs = 150, verbose = False)\n",
        "\t\n",
        "\t# evaluate the model\n",
        "\tscores = model.evaluate(x_train[val], ytrain[val], verbose = False)\n",
        "\tprint(\"%s: %.2f%%\" % (model.metrics_names[1], scores[1]*100))\n",
        "\tcvscores.append(scores[1]*100)\n",
        "print(time.time()-st)\n",
        " \n",
        "print(\"%.2f%% (+/- %.2f%%)\" % (np.mean(cvscores), np.std(cvscores)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b7gVRUn7DiJa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.utils.vis_utils import plot_model\n",
        "\n",
        "clf = Sequential()\n",
        "clf.add(Dense(300, input_dim = 565, activation = 'relu'))\n",
        "clf.add(Dropout(0.2))\n",
        "clf.add(LeakyReLU())\n",
        "clf.add(Dropout(0.3))\n",
        "clf.add(Dense(total, activation = 'softmax'))\n",
        "\n",
        "clf.compile(loss = 'categorical_crossentropy', optimizer = 'adam', metrics = [f1_weighted])\n",
        "\n",
        "plot_model(clf, to_file='model_nn.png', show_shapes=True, show_layer_names=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fALEiyxI-r31",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "st=time.time()\n",
        "model = Sequential()\n",
        "model.add(Dense(300, input_dim = 565, activation = 'relu'))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(LeakyReLU())\n",
        "model.add(Dropout(0.3))\n",
        "model.add(Dense(total, activation = 'softmax'))\n",
        "\n",
        "model.compile(loss = 'categorical_crossentropy', optimizer = 'adam', metrics = [f1_weighted])\n",
        "model.fit(x_train, ytrain, batch_size = 1000, epochs = 150, verbose = False)\n",
        "print(time.time()-st)\n",
        "\n",
        "yt = np.argmax(model.predict(x_train), axis=-1)\n",
        "print(\"Accuracy:\", accuracy_score(y_train, yt))\n",
        "print(\"F1-score:\", f1_score(y_train, yt, average = 'weighted'))\n",
        "\n",
        "yv = np.argmax(model.predict(x_test), axis=-1)\n",
        "print(\"Accuracy:\", accuracy_score(y_test, yv))\n",
        "print(\"F1-score:\", f1_score(y_test, yv, average = 'weighted'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vv3_vii794r7",
        "colab_type": "text"
      },
      "source": [
        "## Confusion Matrix"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "X3ogzs0_cyZ-",
        "colab": {}
      },
      "source": [
        "m = confusion_matrix(y_test, yv, normalize = 'true')\n",
        "tick = sorted(set(y_train))\n",
        "fig, ax = plt.subplots(figsize = (40,20))\n",
        "conf = sns.heatmap(m, cmap=plt.cm.Blues)\n",
        "plt.ylabel('True Label', fontsize = 25)\n",
        "plt.xlabel('Predicted Label', fontsize = 25)\n",
        "conf.set_xticklabels(tick, fontsize = 12)\n",
        "conf.set_yticklabels(tick, fontsize = 12, rotation = 0)\n",
        "conf.xaxis.tick_top()\n",
        "conf.xaxis.set_label_position('top')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KDlKcTaYLoxI",
        "colab_type": "text"
      },
      "source": [
        "# Box Plot"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-LfT4G9LLqEq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def evaluate_model(x, y, model):\n",
        "\tcv = StratifiedKFold(n_splits = 3)\n",
        "\tscores = cross_val_score(model, x, y, scoring = 'f1_weighted', cv = cv, n_jobs = -1)\n",
        "\treturn scores\n",
        "\n",
        "models, names = list(), list()\n",
        "\n",
        "models.append(BernoulliNB(alpha = 100))\n",
        "names.append('BernoulliNB')\n",
        "\n",
        "models.append(ComplementNB(alpha = 184))\n",
        "names.append('ComplementNB')\n",
        "\n",
        "models.append(SGDClassifier(loss = 'log', penalty = 'l1', alpha = 0.0001, n_jobs = -1, random_state = sd))\n",
        "names.append('SGD')\n",
        "\t\n",
        "models.append(LogisticRegression(multi_class = 'multinomial', n_jobs = -1, random_state = sd))\n",
        "names.append('LR')\n",
        "\n",
        "models.append(RandomForestClassifier(n_estimators = 75, min_samples_split = 8, n_jobs = -1, random_state = sd))\n",
        "names.append('RF')\n",
        "\n",
        "models.append(MLPClassifier(hidden_layer_sizes = (75), alpha = 10e-10, early_stopping = True, random_state = sd))\n",
        "names.append('MLP')\n",
        "\n",
        "results = list()\n",
        "for i in range(len(models)):\n",
        "\tscores = evaluate_model(x_train, y_train, models[i])\n",
        "\tresults.append(scores)\n",
        "\n",
        "\tprint('%s: %.3f (%.3f)' % (names[i], np.mean(scores), np.std(scores)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mMX_-1nPNfLH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "plt.figure(figsize = (25,15))\n",
        "plt.boxplot(results, labels = names, showmeans = True)\n",
        "plt.xticks(fontsize = 15)\n",
        "plt.yticks(fontsize = 15)\n",
        "plt.xlabel('Classifiers', fontsize = 20)\n",
        "plt.ylabel('Weighted F1-score', fontsize = 20)\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9mAGw8Zsdy8m",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ClA_h_wrd0JD",
        "colab_type": "text"
      },
      "source": [
        "# Resampling"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VMyCmeQAQ0e6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from collections import Counter\n",
        "from imblearn.under_sampling import RandomUnderSampler\n",
        "from imblearn.over_sampling import RandomOverSampler"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rv23z-5s9K3a",
        "colab_type": "text"
      },
      "source": [
        "## Under-Sampling"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "adbzL3eXa4wp",
        "colab": {}
      },
      "source": [
        "c = Counter(y_train)\n",
        "c[153] = 10000\n",
        "\n",
        "rus = RandomUnderSampler(random_state = sd, sampling_strategy = c)\n",
        "x_rus, y_rus = rus.fit_resample(x_train, y_train)\n",
        "print(sorted(Counter(y_rus).items()))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O4wIo5nM3g7I",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "st=time.time()\n",
        "model = LogisticRegression(multi_class = 'multinomial', n_jobs = -1, random_state = sd).fit(x_rus,y_rus)\n",
        "print(time.time()-st)\n",
        "\n",
        "yt = model.predict(x_rus)\n",
        "print(\"Accuracy:\", accuracy_score(y_rus, yt))\n",
        "print(\"F1-score:\", f1_score(y_rus, yt, average='weighted'))\n",
        "        \n",
        "yv = model.predict(x_test)\n",
        "print(\"Accuracy:\", accuracy_score(y_test, yv))\n",
        "print(\"F1-score:\", f1_score(y_test, yv, average='weighted'))\n",
        "#print(classification_report(y_test, yv, digits=3))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TWZ45x1I9SKm",
        "colab_type": "text"
      },
      "source": [
        "## Over-Sampling"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UkEfSrOIZKH8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "c = Counter(y_train)\n",
        "for item in c:\n",
        "  if c[item] < 100:\n",
        "    c[item] = c[item] + 100\n",
        "\n",
        "ros = RandomOverSampler(random_state = sd, sampling_strategy = c)\n",
        "x_ros, y_ros = ros.fit_resample(x_train, y_train)\n",
        "print(sorted(Counter(y_ros).items()))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aS-jF30K-rKa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "st=time.time()\n",
        "model = LogisticRegression(multi_class = 'multinomial', n_jobs = -1, random_state = sd).fit(x_ros,y_ros)\n",
        "print(time.time()-st)\n",
        "\n",
        "yt = model.predict(x_ros)\n",
        "print(\"Accuracy:\", accuracy_score(y_ros, yt))\n",
        "print(\"F1-score:\", f1_score(y_ros, yt, average='weighted'))\n",
        "        \n",
        "yv = model.predict(x_test)\n",
        "print(\"Accuracy:\", accuracy_score(y_test, yv))\n",
        "print(\"F1-score:\", f1_score(y_test, yv, average='weighted'))\n",
        "#print(classification_report(y_test, yv, digits=3))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7D-s8M_w8A5m",
        "colab_type": "text"
      },
      "source": [
        "## Combination"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JRo5wy9p8DUL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "c = Counter(y_train)\n",
        "for item in c:\n",
        "  if c[item] < 100:\n",
        "    c[item] = c[item] + 100\n",
        "\n",
        "ros = RandomOverSampler(random_state = sd, sampling_strategy = c)\n",
        "x_ros, y_ros = ros.fit_resample(x_train, y_train)\n",
        "\n",
        "c[153] = 10000\n",
        "\n",
        "rus = RandomUnderSampler(random_state = sd, sampling_strategy = c)\n",
        "x_rus, y_rus = rus.fit_resample(x_ros, y_ros)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "rbj9yHN68U8O",
        "colab": {}
      },
      "source": [
        "st=time.time()\n",
        "model = LogisticRegression(multi_class = 'multinomial', n_jobs = -1, random_state = sd).fit(x_rus,y_rus)\n",
        "print(time.time()-st)\n",
        "\n",
        "yt = model.predict(x_rus)\n",
        "print(\"Accuracy:\", accuracy_score(y_rus, yt))\n",
        "print(\"F1-score:\", f1_score(y_rus, yt, average='weighted'))\n",
        "        \n",
        "yv = model.predict(x_test)\n",
        "print(\"Accuracy:\", accuracy_score(y_test, yv))\n",
        "print(\"F1-score:\", f1_score(y_test, yv, average='weighted'))\n",
        "#print(classification_report(y_test, yv, digits=3))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1mStQ_ZXBmP6",
        "colab_type": "text"
      },
      "source": [
        "## Balance Data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6shdwUR935OQ",
        "colab_type": "text"
      },
      "source": [
        "### Remove noise"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2WiO-5XT34CB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data = dataset.copy()\n",
        "ycounts = pd.Series(data['LABEL']).value_counts()\n",
        "noise = ycounts[ycounts < 10].index\n",
        "data = data[~data['LABEL'].isin(noise)]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dRhEGjRtcUZ1",
        "colab_type": "text"
      },
      "source": [
        "### Group minority classes"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t1ivCLEuABhL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#data = dataset.copy()\n",
        "ycounts = pd.Series(data['LABEL']).value_counts()\n",
        "noise = ycounts[ycounts < 50].index\n",
        "data['LABEL'].replace(noise, total, inplace=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ryiq22M1E3Kx",
        "colab_type": "text"
      },
      "source": [
        "### Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "EXMq1zzZEYqd",
        "colab": {}
      },
      "source": [
        "df = data.to_numpy()\n",
        "x = df[:, 1:]\n",
        "y = df[:, 0]\n",
        "\n",
        "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size = 0.2, stratify = y, random_state = sd)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "1gIGsYoIBvEa",
        "colab": {}
      },
      "source": [
        "st=time.time()\n",
        "model = LogisticRegression(multi_class = 'multinomial', n_jobs = -1, random_state = sd).fit(x_train,y_train)\n",
        "print(time.time()-st)\n",
        "\n",
        "yt = model.predict(x_train)\n",
        "print(\"Accuracy:\", accuracy_score(y_train, yt))\n",
        "print(\"F1-score:\", f1_score(y_train, yt, average='weighted'))\n",
        "        \n",
        "yv = model.predict(x_test)\n",
        "print(\"Accuracy:\", accuracy_score(y_test, yv))\n",
        "print(\"F1-score:\", f1_score(y_test, yv, average='weighted'))\n",
        "#print(classification_report(y_test, yv, digits=3))"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}