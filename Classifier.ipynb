{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.3"
    },
    "colab": {
      "name": "Classifier.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yyJV5NALu2u-",
        "colab_type": "text"
      },
      "source": [
        "# Import libraries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L3adVzKZPxEa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "total = 217\n",
        "import time\n",
        "import numpy as np\n",
        "from numpy.random import seed\n",
        "sd = 30\n",
        "seed(sd)\n",
        "\n",
        "import pandas as pd\n",
        "import matplotlib as mpl\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "%tensorflow_version 2.x\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from keras import metrics\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, LSTM, GRU\n",
        "from keras.layers import LeakyReLU, Input, Dropout\n",
        "from keras.utils import to_categorical\n",
        "from keras.callbacks import EarlyStopping\n",
        "from keras.wrappers.scikit_learn import KerasClassifier\n",
        "\n",
        "import sklearn\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.metrics import plot_confusion_matrix\n",
        "from sklearn.metrics import f1_score\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.model_selection import KFold\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "from sklearn.linear_model import SGDClassifier\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "from sklearn.naive_bayes import ComplementNB\n",
        "from sklearn.naive_bayes import BernoulliNB\n",
        "from sklearn.naive_bayes import CategoricalNB\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.neural_network import MLPClassifier"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kn7an7Suu6pP",
        "colab_type": "text"
      },
      "source": [
        "# Load Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_agzTMADnilR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "%cd drive/My Drive/partilhado/\n",
        "\n",
        "dataset = pd.read_csv('dataset-final.csv', sep=',')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tvP0bRPekqEt",
        "colab_type": "text"
      },
      "source": [
        "# Split Data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KlViGwj-a-Y0",
        "colab_type": "text"
      },
      "source": [
        "## Remove noise"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-GqPe1MxbCwN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "ycounts = pd.Series(dataset['LABEL']).value_counts()\n",
        "noise = ycounts[ycounts < 2].index\n",
        "dataset = dataset[~dataset['LABEL'].isin(noise)]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kDFZS9rzQzkP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df = dataset.to_numpy()\n",
        "x = df[:, 1:] #all columns except the first one (features)\n",
        "y = df[:, 0] #only the first column (labels)\n",
        "\n",
        "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size = 0.2, random_state = sd)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eGjRwnDh4939",
        "colab_type": "text"
      },
      "source": [
        "# Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "21z1Ldv2jJSR",
        "colab": {}
      },
      "source": [
        "st=time.time()\n",
        "#model = LogisticRegression(multi_class = 'multinomial', n_jobs = -1, random_state = sd).fit(x_train,y_train)\n",
        "#model = RandomForestClassifier(n_estimators = 75, min_samples_split = 8, n_jobs = -1, random_state = sd).fit(x_train,y_train)\n",
        "model = MLPClassifier(hidden_layer_sizes = (75), alpha = 10e-10, early_stopping = True, random_state = sd).fit(x_train,y_train)\n",
        "print(time.time()-st)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cKIRLOHTFqS3",
        "colab_type": "text"
      },
      "source": [
        "## Predict"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sWTeZaN9RzLd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def predict(alg, sample, return_prob=False):\n",
        "  x = sample.reshape(1,-1)\n",
        "  probs = alg.predict_proba(x)[0]\n",
        "  idx = np.argsort(-probs)[:3]\n",
        "  labels = alg.classes_\n",
        "\n",
        "  if return_prob:\n",
        "    return [labels[idx].tolist(),probs[idx].tolist()]\n",
        "\n",
        "  return labels[idx]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P-7PaYypMlCB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "xt = x_test[0]\n",
        "yt = y_test[0]\n",
        "\n",
        "print(predict(model, xt, return_prob=True))\n",
        "print(yt)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lQSaSyc1qo6C",
        "colab_type": "text"
      },
      "source": [
        "## Evaluate"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "f0dnyBc4qqBz",
        "colab": {}
      },
      "source": [
        "def evaluate(alg, xset, yset):\n",
        "  tp = 0\n",
        "  nrow = xset.shape[0] \n",
        "  for i in range(nrow):\n",
        "    labels = predict(alg,xset[i])\n",
        "    if yset[i] in labels:\n",
        "      tp += 1\n",
        "  return tp/nrow"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "cfaZNcx3quyg",
        "colab": {}
      },
      "source": [
        "evaluate(model, x_test, y_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-9Yi3GHPoWQh",
        "colab_type": "text"
      },
      "source": [
        "# Model NN"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "owKv_wCiqSlX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras import backend as K\n",
        "\n",
        "def f1_weighted(true, pred):\n",
        "\n",
        "    predLabels = K.argmax(pred, axis=-1)\n",
        "    pred = K.one_hot(predLabels, total) \n",
        "\n",
        "    actual_positives = K.sum(true, axis=0)       # = TP + FN\n",
        "    pred_positives = K.sum(pred, axis=0)         # = TP + FP\n",
        "    true_positives = K.sum(true * pred, axis=0)  # = TP\n",
        "\n",
        "    precision = (true_positives + K.epsilon()) / (pred_positives + K.epsilon()) \n",
        "    recall = (true_positives + K.epsilon()) / (actual_positives + K.epsilon()) \n",
        "        #both = 1 if ground_positives == 0 or pred_positives == 0\n",
        "\n",
        "    f1 = 2 * (precision * recall) / (precision + recall)\n",
        "\n",
        "    weighted_f1 = f1 * actual_positives / K.sum(actual_positives)\n",
        "    weighted_f1 = K.sum(weighted_f1)\n",
        "\n",
        "    return weighted_f1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "2uiJ2qFsoXpN",
        "colab": {}
      },
      "source": [
        "ytrain = to_categorical(y_train, num_classes = total)\n",
        "#es = EarlyStopping(monitor='val_loss', mode='min', verbose=False)\n",
        "\n",
        "st=time.time()\n",
        "model_NN = Sequential()\n",
        "model_NN.add(Dense(300, input_dim=565, activation='relu'))\n",
        "model_NN.add(Dropout(0.2))\n",
        "model_NN.add(LeakyReLU())\n",
        "model_NN.add(Dropout(0.3))\n",
        "model_NN.add(Dense(total, activation='softmax'))\n",
        "\n",
        "model_NN.compile(loss = 'categorical_crossentropy', optimizer = 'adam', metrics = [f1_weighted])\n",
        "model_NN.fit(x_train, ytrain, batch_size = 1000, epochs = 150, verbose = False)\n",
        "print(time.time()-st)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4-TNVoddoYsq",
        "colab_type": "text"
      },
      "source": [
        "## Predict"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "7_HxnpCToeOU",
        "colab": {}
      },
      "source": [
        "def predict_NN(alg, sample, return_prob=False):\n",
        "  x = sample.reshape(1,-1)\n",
        "  probs = alg.predict(x)[0]\n",
        "  labels = np.argsort(-probs)[:3]\n",
        "\n",
        "  if return_prob:\n",
        "    return [labels.tolist(),probs[labels].tolist()]\n",
        "\n",
        "  return labels"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HZTZvuMUU0GQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "xt = x_test[0]\n",
        "yt = y_test[0]\n",
        "\n",
        "print(predict_NN(model_NN, xt, return_prob=True))\n",
        "print(yt)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0ZKzoE7Rqyou",
        "colab_type": "text"
      },
      "source": [
        "## Evaluate"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "SLczNJ70q23R",
        "colab": {}
      },
      "source": [
        "def evaluate_NN(alg, xset, yset):\n",
        "  tp = 0\n",
        "  nrow = xset.shape[0]\n",
        "  for i in range(nrow):\n",
        "    labels = predict_NN(alg,xset[i])\n",
        "    if yset[i] in labels:\n",
        "      tp += 1\n",
        "  return tp/nrow"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Wb1hQZqiq9iY",
        "colab": {}
      },
      "source": [
        "evaluate_NN(model_NN, x_test, y_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xDORgi78AsH8",
        "colab_type": "text"
      },
      "source": [
        "# Multi-step Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "u9f3y8vrl-UF",
        "colab": {}
      },
      "source": [
        "from keras import backend as K\n",
        "\n",
        "def f1_weighted(true, pred):\n",
        "\n",
        "    predLabels = K.argmax(pred, axis=-1)\n",
        "    pred = K.one_hot(predLabels, total) \n",
        "\n",
        "    actual_positives = K.sum(true, axis=0)       # = TP + FN\n",
        "    pred_positives = K.sum(pred, axis=0)         # = TP + FP\n",
        "    true_positives = K.sum(true * pred, axis=0)  # = TP\n",
        "\n",
        "    precision = (true_positives + K.epsilon()) / (pred_positives + K.epsilon()) \n",
        "    recall = (true_positives + K.epsilon()) / (actual_positives + K.epsilon()) \n",
        "        #both = 1 if ground_positives == 0 or pred_positives == 0\n",
        "\n",
        "    f1 = 2 * (precision * recall) / (precision + recall)\n",
        "\n",
        "    weighted_f1 = f1 * actual_positives / K.sum(actual_positives)\n",
        "    weighted_f1 = K.sum(weighted_f1)\n",
        "\n",
        "    return weighted_f1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aYHaasiPjw-2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def models(x,y):\n",
        "  model = []\n",
        "\n",
        "  #PASSO 1\n",
        "  y1 = np.where(y != 153, total, y)\n",
        "  clf1 = MLPClassifier(hidden_layer_sizes = (50), early_stopping = True, random_state = sd).fit(x,y1)\n",
        "  model.append(clf1)\n",
        "  \n",
        "  #PASSO 2\n",
        "  ind = np.nonzero(y != 153)\n",
        "  x2 = x[ind]\n",
        "  y2 = y[ind]\n",
        "  keys, counts = np.unique(y2, return_counts=True)\n",
        "  ind = np.argsort(-counts)\n",
        "  keys = keys[ind]\n",
        "  counts = counts[ind]\n",
        "  ybar = counts.cumsum()/sum(counts)\n",
        "  other = []\n",
        "  for i in range(len(keys)):\n",
        "    if ybar[i] > 0.5:\n",
        "      other.append(keys[i])\n",
        "  y2 = np.where(np.isin(y2,other), total, y2)\n",
        "  clf2 = MLPClassifier(hidden_layer_sizes = (75), alpha = 10e-10, early_stopping = True, random_state = sd).fit(x2,y2)\n",
        "  model.append(clf2)\n",
        "\n",
        "  #PASSO 3\n",
        "  ind = np.nonzero(np.isin(y, other))\n",
        "  x3 = x[ind]\n",
        "  y3 = y[ind]\n",
        "  keys, counts = np.unique(y3, return_counts = True)\n",
        "  ind = np.argsort(-counts)\n",
        "  keys = keys[ind]\n",
        "  counts = counts[ind]\n",
        "  ybar = counts.cumsum()/sum(counts)\n",
        "  other = []\n",
        "  for i in range(len(keys)):\n",
        "    if ybar[i] > 0.7:\n",
        "      other.append(keys[i])\n",
        "  y3 = np.where(np.isin(y3, other), total, y3)\n",
        "  clf3 = LogisticRegression(multi_class = 'multinomial', n_jobs = -1, random_state = sd).fit(x3,y3)\n",
        "  model.append(clf3)\n",
        "\n",
        "  #PASSO 4\n",
        "  ind = np.nonzero(np.isin(y, other))\n",
        "  x4 = x[ind]\n",
        "  y4 = y[ind]\n",
        "  y4 = to_categorical(y4, num_classes = total)\n",
        "\n",
        "  clf4 = Sequential()\n",
        "  clf4.add(Dense(300, input_dim = 565, activation = 'relu'))\n",
        "  clf4.add(LeakyReLU())\n",
        "  clf4.add(Dropout(0.5))\n",
        "  clf4.add(Dense(total, activation = 'softmax'))\n",
        "\n",
        "  clf4.compile(loss = 'categorical_crossentropy', optimizer = 'adam', metrics = [f1_weighted])\n",
        "  clf4.fit(x4, y4, batch_size = 400, epochs = 100, verbose = False)\n",
        "  model.append(clf4)\n",
        "\n",
        "  return model\n",
        "\n",
        "m_steps = models(x_train,y_train)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "X9nl3oOJHG5e"
      },
      "source": [
        "## Predict"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "u1RZMO9Bn-5e",
        "colab": {}
      },
      "source": [
        "def predict_steps(algs, sample, return_prob=False):\n",
        "  probs = {}\n",
        "  m1,m2,m3,m4 = algs\n",
        "  x = sample.reshape(1,-1)\n",
        "  \n",
        "  p1 = m1.predict_proba(x)[0]\n",
        "  probs['153'] = p1[0]\n",
        "  p = p1[1]\n",
        "\n",
        "  p2 = m2.predict_proba(x)[0]\n",
        "  lb2 = m2.classes_[:-1]\n",
        "  for i in range(len(lb2)):\n",
        "    probs[str(lb2[i])] = p2[i]*p\n",
        "  p = p2[-1]*p\n",
        "\n",
        "  p3 = m3.predict_proba(x)[0]\n",
        "  lb3 = m3.classes_[:-1]\n",
        "  for i in range(len(lb3)):\n",
        "    probs[str(lb3[i])] = p3[i]*p\n",
        "  p = p3[-1]*p\n",
        "\n",
        "  p4 = m4.predict(x)[0]\n",
        "  l = np.concatenate((np.array([153]), lb2, lb3), axis=None)\n",
        "  lb4 = np.setdiff1d(np.arange(total),l)\n",
        "  for i in range(len(lb4)):\n",
        "    probs[str(lb4[i])] = p4[i]*p\n",
        "\n",
        "  k = sorted(probs, key=probs.get, reverse=True)[:3]\n",
        "  top = [int(i) for i in k]\n",
        "\n",
        "  if return_prob:\n",
        "    p = [probs[x] for x in k]\n",
        "    return [top,p]\n",
        "\n",
        "  return top"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6vt_kWOJVWD1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "xt = x_test[15]\n",
        "yt = y_test[15]\n",
        "\n",
        "print(predict_steps(m_steps, xt, return_prob=True))\n",
        "print(yt)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7CvtLCBTVMH6",
        "colab_type": "text"
      },
      "source": [
        "## Evaluate"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "joIgtSWfUSRf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def evaluate_steps(algs, xset, yset):\n",
        "  tp = 0\n",
        "  nrow = xset.shape[0] \n",
        "  for i in range(nrow):\n",
        "    labels = predict_steps(algs, xset[i])\n",
        "    if yset[i] in labels:\n",
        "      tp += 1\n",
        "  return tp/nrow"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LgsVbFAxUbhw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "evaluate_steps(m_steps, x_test, y_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WNK54k0oPm6w",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def acc(algs, xset, yset):\n",
        "  tp = 0\n",
        "  nrow = xset.shape[0] \n",
        "  for i in range(nrow):\n",
        "    labels = predict_steps(algs, xset[i])\n",
        "    if yset[i] == labels[0]:\n",
        "      tp += 1\n",
        "  return tp/nrow\n",
        "\n",
        "acc(m_steps, x_test, y_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "97K_1XukPFYF",
        "colab": {}
      },
      "source": [
        "def f1_score(algs, xset, yset, epsilon=10e-5):\n",
        "  tp = np.zeros(total)\n",
        "  fn = np.zeros(total)\n",
        "  fp = np.zeros(total)\n",
        "  nrow = xset.shape[0]\n",
        "\n",
        "  for i in range(nrow):\n",
        "    true = yset[i]\n",
        "    pred = predict_steps(algs, xset[i])[0]\n",
        "\n",
        "    if true == pred:\n",
        "      tp[true] += 1\n",
        "    else:\n",
        "      fn[true] += 1\n",
        "      fp[pred] += 1\n",
        "\n",
        "  totaltrue = tp + fn\n",
        "  totalpred = tp + fp\n",
        "  precision = (tp + epsilon) / (totalpred + epsilon)\n",
        "  recall = (tp + epsilon) / (totaltrue + epsilon)\n",
        "\n",
        "  f1 = 2 * (precision * recall) / (precision + recall)\n",
        "\n",
        "  weighted_f1 = f1 * (totaltrue / np.sum(totaltrue))\n",
        "  weighted_f1 = np.sum(weighted_f1)\n",
        "\n",
        "  return weighted_f1\n",
        "\n",
        "f1_score(m_steps, x_test, y_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A3wLPGZwO5JG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}