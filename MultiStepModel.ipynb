{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.3"
    },
    "colab": {
      "name": "MultiStepModel.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "irOeotTLvARN"
      ],
      "toc_visible": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yyJV5NALu2u-",
        "colab_type": "text"
      },
      "source": [
        "# Import libraries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L3adVzKZPxEa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "total = 217\n",
        "\n",
        "import time\n",
        "import numpy as np\n",
        "from numpy.random import seed\n",
        "sd = 30\n",
        "seed(sd)\n",
        "\n",
        "import pandas as pd\n",
        "import matplotlib as mpl\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "%tensorflow_version 2.x\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from keras import metrics\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, LSTM, GRU\n",
        "from keras.layers import LeakyReLU, Input, Dropout\n",
        "from keras.utils import to_categorical\n",
        "from keras.callbacks import EarlyStopping\n",
        "from keras.wrappers.scikit_learn import KerasClassifier\n",
        "\n",
        "import sklearn\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.metrics import plot_confusion_matrix\n",
        "from sklearn.metrics import f1_score\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.model_selection import validation_curve\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.model_selection import KFold\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "from sklearn.linear_model import SGDClassifier\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.neural_network import MLPClassifier"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kn7an7Suu6pP",
        "colab_type": "text"
      },
      "source": [
        "# Load Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_agzTMADnilR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "%cd drive/My Drive/partilhado/\n",
        "\n",
        "dataset = pd.read_csv('dataset-final.csv', sep=',')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zJ5utcd_bOFq",
        "colab_type": "text"
      },
      "source": [
        "# Remove noise"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Up_gajKzbQOi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "ycounts = pd.Series(dataset['LABEL']).value_counts()\n",
        "noise = ycounts[ycounts < 2].index\n",
        "dataset = dataset[~dataset['LABEL'].isin(noise)]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "irOeotTLvARN",
        "colab_type": "text"
      },
      "source": [
        "# Class Distribution"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_yngb5CEPxEw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "ycounts = pd.Series(dataset['LABEL']).value_counts()\n",
        "ybar = ycounts/sum(ycounts)\n",
        "ybar.plot(kind = 'bar',figsize=(25,10))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0oItE6acPxE8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "ycounts = pd.Series(dataset['LABEL']).value_counts()\n",
        "ybar = ycounts.cumsum()/sum(ycounts)\n",
        "ybar.plot(kind = 'bar',figsize=(25,10))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gDTGYyzejbTE",
        "colab_type": "text"
      },
      "source": [
        "# Classify 153 and rest"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aYHaasiPjw-2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data = dataset.copy()\n",
        "l = list(range(0,total))\n",
        "l.remove(153)\n",
        "data['LABEL'].replace(l, 0, inplace=True)\n",
        "data['LABEL'].replace(153, 1, inplace=True)\n",
        "\n",
        "ycounts = pd.Series(data['LABEL']).value_counts()\n",
        "ybar = ycounts/sum(ycounts)\n",
        "ax = ybar.plot(kind = 'bar', figsize = (15,10))\n",
        "ax.set_xticklabels(['other', 153], rotation = 0, fontsize = 15)\n",
        "ax.set_ylabel('Relative Frequency', fontsize = 15)\n",
        "ax.set_xlabel('Labels', fontsize = 15)\n",
        "\n",
        "df = data.to_numpy()\n",
        "x = df[:, 1:]\n",
        "y = df[:, 0]\n",
        "\n",
        "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size = 0.2, stratify = y, random_state = sd)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SJAah5qytabx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "st=time.time()\n",
        "#model = LogisticRegression(n_jobs = -1, random_state = sd)\n",
        "#model = SGDClassifier(n_jobs = -1, random_state = sd)\n",
        "#model = RandomForestClassifier(n_estimators = 75, min_samples_split = 8, n_jobs = -1, random_state = sd)\n",
        "model = MLPClassifier(hidden_layer_sizes = (30), early_stopping = True, random_state = sd)\n",
        "\n",
        "kfold = StratifiedKFold(n_splits = 3)\n",
        "results = cross_val_score(model, x_train, y_train, cv = kfold, scoring = 'f1_weighted')\n",
        "print(time.time()-st)\n",
        "\n",
        "print('F1-score: {:4.2f}% (+-{:3.2f}%)'.format(results.mean()*100, results.std()*100))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O_aeSKZ4d8sO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = MLPClassifier(hidden_layer_sizes = (30), early_stopping = True, random_state = sd).fit(x_train, y_train)\n",
        "\n",
        "yt = model.predict(x_train)\n",
        "print(\"Accuracy:\", accuracy_score(y_train, yt))\n",
        "print(\"F1-score:\", f1_score(y_train, yt, average = 'weighted'))\n",
        "        \n",
        "yv = model.predict(x_test)\n",
        "print(\"Accuracy:\", accuracy_score(y_test, yv))\n",
        "print(\"F1-score:\", f1_score(y_test, yv, average = 'weighted'))\n",
        "print(classification_report(y_test, yv, digits=3))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "BmzLXHLUL4td"
      },
      "source": [
        "## Confusion Matrix"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "0X6ChzZ6L4ti",
        "colab": {}
      },
      "source": [
        "m = confusion_matrix(y_test, yv, normalize = 'true')\n",
        "tick = ['other', 153]\n",
        "fig, ax = plt.subplots(figsize = (30,15))\n",
        "conf = sns.heatmap(m, cmap=plt.cm.Blues)\n",
        "plt.ylabel('True Label', fontsize = 25)\n",
        "plt.xlabel('Predicted Label', fontsize = 25)\n",
        "conf.set_xticklabels(tick, fontsize = 25)\n",
        "conf.set_yticklabels(tick, fontsize = 25)\n",
        "conf.xaxis.tick_top()\n",
        "conf.xaxis.set_label_position('top')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0VeBuk0E_PrK",
        "colab_type": "text"
      },
      "source": [
        "# Group over 50%"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xwSrJWyvPxFE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data = dataset.copy()\n",
        "data = data[data['LABEL'] != 153]\n",
        "ycounts = pd.Series(data['LABEL']).value_counts()\n",
        "ybar = ycounts.cumsum()/sum(ycounts)\n",
        "\n",
        "df = data.to_numpy()\n",
        "x = df[:, 1:]\n",
        "y = df[:, 0]\n",
        "\n",
        "ykeys = ycounts.keys()\n",
        "\n",
        "yother = []\n",
        "for i in range(len(ycounts)):\n",
        "  if ybar.get(key = ykeys[i]) > 0.5:\n",
        "    yother.append(ykeys[i])\n",
        "\n",
        "ylabels=[total if y[i] in yother else j for i,j in enumerate(y)]\n",
        "\n",
        "ycounts = pd.Series(ylabels).value_counts()\n",
        "ybar = ycounts/sum(ycounts)\n",
        "ax = ybar.plot(kind = 'bar', figsize = (15,10))\n",
        "ax.set_xticklabels(['other', 53, 32, 111], rotation = 0, fontsize = 15)\n",
        "ax.set_ylabel('Relative Frequency', fontsize = 15)\n",
        "ax.set_xlabel('Labels', fontsize = 15)\n",
        "\n",
        "x_train, x_test, y_train, y_test = train_test_split(x, ylabels, test_size = 0.2, stratify = ylabels, random_state = sd)\n",
        "\n",
        "lst1 = sorted(set(y_test))\n",
        "lst1.remove(total)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qh_l6--TPxFN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "st=time.time()\n",
        "#model = LogisticRegression(multi_class = 'multinomial', n_jobs = -1, random_state = sd)\n",
        "#model = SGDClassifier(loss = 'log', penalty = 'l1', alpha = 0.0001, n_jobs = -1, random_state = sd)\n",
        "#model = RandomForestClassifier(n_estimators = 75, min_samples_split = 8, n_jobs = -1, random_state = sd)\n",
        "model = MLPClassifier(hidden_layer_sizes = (50), alpha = 10e-10, early_stopping = True, random_state = sd)\n",
        "\n",
        "kfold = StratifiedKFold(n_splits = 3)\n",
        "results = cross_val_score(model, x_train, y_train, cv = kfold, scoring = 'f1_weighted')\n",
        "print(time.time()-st)\n",
        "\n",
        "print('F1-score: {:4.2f}% (+-{:3.2f}%)'.format(results.mean()*100, results.std()*100))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T0g53ZzDjChL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = MLPClassifier(hidden_layer_sizes = (50), alpha = 10e-10, early_stopping = True, random_state = sd).fit(x_train, y_train)\n",
        "\n",
        "yt = model.predict(x_train)\n",
        "print(\"Accuracy:\", accuracy_score(y_train, yt))\n",
        "print(\"F1-score:\", f1_score(y_train, yt, average = 'weighted'))\n",
        "        \n",
        "yv = model.predict(x_test)\n",
        "print(\"Accuracy:\", accuracy_score(y_test, yv))\n",
        "print(\"F1-score:\", f1_score(y_test, yv, average = 'weighted'))\n",
        "print(classification_report(y_test, yv, digits=3))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "HYji5O84Y0Oy"
      },
      "source": [
        "## Confusion Matrix"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "MQbMGXFJY0O0",
        "colab": {}
      },
      "source": [
        "m = confusion_matrix(y_test, yv, normalize = 'true')\n",
        "tick = lst1 + ['other']\n",
        "fig, ax = plt.subplots(figsize=(30,15))\n",
        "conf = sns.heatmap(m, cmap=plt.cm.Blues)\n",
        "plt.ylabel('True Label', fontsize = 25)\n",
        "plt.xlabel('Predicted Label', fontsize = 25)\n",
        "conf.set_xticklabels(tick, fontsize = 25)\n",
        "conf.set_yticklabels(tick, fontsize = 25)\n",
        "conf.xaxis.tick_top()\n",
        "conf.xaxis.set_label_position('top')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hgbjeK0q5QBB",
        "colab_type": "text"
      },
      "source": [
        "# Group over 70%"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "KIQ3_mwm5nmg",
        "colab": {}
      },
      "source": [
        "data = dataset.copy()\n",
        "data = data[~data.LABEL.isin([153] + lst1)]\n",
        "ycounts = pd.Series(data['LABEL']).value_counts()\n",
        "ybar = ycounts.cumsum()/sum(ycounts)\n",
        "\n",
        "df = data.to_numpy()\n",
        "x = df[:, 1:]\n",
        "y = df[:, 0]\n",
        "\n",
        "ykeys = ycounts.keys()\n",
        "\n",
        "yother = []\n",
        "for i in range(len(ycounts)):\n",
        "  if ybar.get(key = ykeys[i]) > 0.7:\n",
        "    yother.append(ykeys[i])\n",
        "\n",
        "ylabels=[total if y[i] in yother else j for i,j in enumerate(y)]\n",
        "\n",
        "ycounts = pd.Series(ylabels).value_counts()\n",
        "ybar = ycounts/sum(ycounts)\n",
        "ax = ybar.plot(kind = 'bar', figsize = (15,10))\n",
        "ax.set_xticklabels(['other', 176, 4, 143, 44, 145, 169, 167, 114, 25, 137, 2, 149], rotation = 0, fontsize = 13)\n",
        "ax.set_ylabel('Relative Frequency', fontsize = 15)\n",
        "ax.set_xlabel('Labels', fontsize = 15)\n",
        "\n",
        "x_train, x_test, y_train, y_test = train_test_split(x, ylabels, test_size = 0.2, stratify = ylabels, random_state = sd)\n",
        "\n",
        "lst2 = sorted(set(y_test))\n",
        "lst2.remove(total)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "lHwEC3Yi-55T",
        "colab": {}
      },
      "source": [
        "st=time.time()\n",
        "model = LogisticRegression(multi_class = 'multinomial', n_jobs = -1, random_state = sd)\n",
        "#model = SGDClassifier(loss = 'log', penalty = 'l1', alpha = 0.0001, n_jobs = -1, random_state = sd)\n",
        "#model = RandomForestClassifier(n_estimators = 75, min_samples_split = 8, n_jobs = -1, random_state = sd)\n",
        "#model = MLPClassifier(hidden_layer_sizes = (75), alpha = 10e-10, early_stopping = True, random_state = sd)\n",
        "\n",
        "kfold = StratifiedKFold(n_splits = 3)\n",
        "results = cross_val_score(model, x_train, y_train, cv = kfold, scoring = 'f1_weighted')\n",
        "print(time.time()-st)\n",
        "\n",
        "print('F1-score: {:4.2f}% (+-{:3.2f}%)'.format(results.mean()*100, results.std()*100))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GO6QXCQ9jP81",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = LogisticRegression(multi_class = 'multinomial', n_jobs = -1, random_state = sd).fit(x_train, y_train)\n",
        "\n",
        "yt = model.predict(x_train)\n",
        "print(\"Accuracy:\", accuracy_score(y_train, yt))\n",
        "print(\"F1-score:\", f1_score(y_train, yt, average = 'weighted'))\n",
        "        \n",
        "yv = model.predict(x_test)\n",
        "print(\"Accuracy:\", accuracy_score(y_test, yv))\n",
        "print(\"F1-score:\", f1_score(y_test, yv, average = 'weighted'))\n",
        "#print(classification_report(y_test, yv, digits=3))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EYRetWGm9Bmn",
        "colab_type": "text"
      },
      "source": [
        "## Confusion Matrix"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "QpT3jQy3hxY_",
        "colab": {}
      },
      "source": [
        "m = confusion_matrix(y_test, yv, normalize = 'true')\n",
        "tick = lst2 + ['other']\n",
        "fig, ax = plt.subplots(figsize = (30,15))\n",
        "conf = sns.heatmap(m, cmap=plt.cm.Blues)\n",
        "plt.ylabel('True Label', fontsize = 25)\n",
        "plt.xlabel('Predicted Label', fontsize = 25)\n",
        "conf.set_xticklabels(tick, fontsize = 20)\n",
        "conf.set_yticklabels(tick, fontsize = 20)\n",
        "conf.xaxis.tick_top()\n",
        "conf.xaxis.set_label_position('top')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xpjh-e4XhhIQ",
        "colab_type": "text"
      },
      "source": [
        "# Classify the rest"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "M6AWi17D4Djb",
        "colab": {}
      },
      "source": [
        "data = dataset.copy()\n",
        "cumlst = lst1 + lst2\n",
        "data = data[~data.LABEL.isin([153] + cumlst)]\n",
        "ycounts = pd.Series(data['LABEL']).value_counts()\n",
        "ybar = ycounts/sum(ycounts)\n",
        "\n",
        "ax = ybar.plot(kind = 'bar', figsize = (20,10))\n",
        "ax.set_ylabel('Relative Frequency', fontsize = 15)\n",
        "ax.set_xlabel('Labels', fontsize = 15)\n",
        "ax.set_xticklabels(ycounts.keys(), fontsize = 12)\n",
        "\n",
        "df = data.to_numpy()\n",
        "x = df[:, 1:] #all columns except the first one (features)\n",
        "y = df[:, 0] #only the first column (labels)\n",
        "\n",
        "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size = 0.2, random_state = sd)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "owKv_wCiqSlX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras import backend as K\n",
        "\n",
        "def f1_weighted(true, pred):\n",
        "\n",
        "    predLabels = K.argmax(pred, axis=-1)\n",
        "    pred = K.one_hot(predLabels, total) \n",
        "\n",
        "    actual_positives = K.sum(true, axis=0)       # = TP + FN\n",
        "    pred_positives = K.sum(pred, axis=0)         # = TP + FP\n",
        "    true_positives = K.sum(true * pred, axis=0)  # = TP\n",
        "\n",
        "    precision = (true_positives + K.epsilon()) / (pred_positives + K.epsilon()) \n",
        "    recall = (true_positives + K.epsilon()) / (actual_positives + K.epsilon()) \n",
        "        #both = 1 if ground_positives == 0 or pred_positives == 0\n",
        "\n",
        "    f1 = 2 * (precision * recall) / (precision + recall)\n",
        "\n",
        "    weighted_f1 = f1 * actual_positives / K.sum(actual_positives)\n",
        "    weighted_f1 = K.sum(weighted_f1)\n",
        "\n",
        "    return weighted_f1\n",
        "\n",
        "ytrain = to_categorical(y_train, num_classes = total)\n",
        "ytest = to_categorical(y_test, num_classes = total)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Un7anfuieY5D",
        "colab": {}
      },
      "source": [
        "kfold = StratifiedKFold(n_splits = 10)\n",
        "cvscores = []\n",
        "\n",
        "st=time.time()\n",
        "for train, val in kfold.split(x_train, y_train):\n",
        "  # create model\n",
        "  model = Sequential()\n",
        "  model.add(Dense(300, input_dim = 565, activation = 'relu'))\n",
        "  model.add(LeakyReLU())\n",
        "  model.add(Dropout(0.5))\n",
        "  model.add(Dense(total, activation = 'softmax'))\n",
        "\n",
        "  model.compile(loss = 'categorical_crossentropy', optimizer = 'adam', metrics = [f1_weighted])\n",
        "  model.fit(x_train[train], ytrain[train], batch_size = 400, epochs = 100, verbose = False)\n",
        "\t\n",
        "  # evaluate the model\n",
        "  scores = model.evaluate(x_train[val], ytrain[val], verbose = False)\n",
        "  print(\"%s: %.2f%%\" % (model.metrics_names[1], scores[1]*100))\n",
        "  cvscores.append(scores[1]*100)\n",
        "print(time.time()-st)\n",
        " \n",
        "print(\"%.2f%% (+/- %.2f%%)\" % (np.mean(cvscores), np.std(cvscores)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qt_pdGTMguyW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = Sequential()\n",
        "model.add(Dense(300, input_dim = 565, activation = 'relu'))\n",
        "model.add(LeakyReLU())\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(total, activation = 'softmax'))\n",
        "\n",
        "model.compile(loss = 'categorical_crossentropy', optimizer = 'adam', metrics = [f1_weighted])\n",
        "model.fit(x_train, ytrain, batch_size = 400, epochs = 100, verbose = False)\n",
        "\n",
        "yt = np.argmax(model.predict(x_train), axis=-1)\n",
        "print(\"Accuracy:\", accuracy_score(y_train, yt))\n",
        "print(\"F1-score:\", f1_score(y_train, yt, average = 'weighted'))\n",
        "\n",
        "yv = np.argmax(model.predict(x_test), axis=-1)\n",
        "print(\"Accuracy:\", accuracy_score(y_test, yv))\n",
        "print(\"F1-score:\", f1_score(y_test, yv, average = 'weighted'))\n",
        "#print(classification_report(y_test, yv, digits=3))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vv3_vii794r7",
        "colab_type": "text"
      },
      "source": [
        "## Confusion Matrix"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "X3ogzs0_cyZ-",
        "colab": {}
      },
      "source": [
        "m = confusion_matrix(y_test, yv, normalize = 'true')\n",
        "tick = sorted(set(y_train))\n",
        "fig, ax = plt.subplots(figsize = (40,20))\n",
        "conf = sns.heatmap(m, cmap=plt.cm.Blues)\n",
        "plt.ylabel('True Label', fontsize = 25)\n",
        "plt.xlabel('Predicted Label', fontsize = 25)\n",
        "conf.set_xticklabels(tick, fontsize = 12)\n",
        "conf.set_yticklabels(tick, fontsize = 12, rotation = 0)\n",
        "conf.xaxis.tick_top()\n",
        "conf.xaxis.set_label_position('top')"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}